Name:  1subj_1e1_25steps_2fch_app3_ Lr_rate:  0.001 Use Teacher:  False  Riter:  25  Subjs:  1
Using device: cuda:0
/scratch_net/biwidl214/jonatank/anaconda3/envs/JKMT/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'networks.vae_bilinear_conv.ResBlock_Down' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/scratch_net/biwidl214/jonatank/anaconda3/envs/JKMT/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'networks.vae_bilinear_conv.ResBlock_Up' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
['Brats17_CBICA_AXM_1_t2_unbiased.nii.gz']
Loading train set for subj
Subject  Brats17_CBICA_AXM_1_t2_unbiased.nii.gz  Number of Slices:  137
AUC :  0.6491971226773727
AUC :  0.7056221283619084
AUC :  0.7083651772136369
AUC :  0.613523815172624
AUC :  0.668361221116685
AUC :  0.7485084093699212
AUC :  0.7269126708782104
AUC :  0.7257800866897763
AUC :  0.686150323342704
AUC :  0.777373360672406
AUC :  0.6691700519868601
AUC :  0.6901894009341533
AUC :  0.662691928171498
AUC :  0.6635781869880281
AUC :  0.6475164616777215
AUC :  0.7130241249391228
AUC :  0.6764667895594949
AUC :  0.695876856361815
AUC :  0.7018342715419841
AUC :  0.6734432454323873
AUC :  0.5908756401729338
AUC :  0.563028653284841
AUC :  0.5945282297358585
AUC :  0.603761013657291
AUC :  0.6628582049689384
AUC :  0.6276457875385804
AUC :  0.6129878668799947
AUC :  0.618261630718811
AUC :  0.6625554395157988
AUC :  0.5768756009903747
AUC :  0.7678305171859683
AUC :  0.7474915580081295
AUC :  0.7274332539338225
AUC :  0.6028729245252669
AUC :  0.5846043345660684
AUC :  0.719780265999274
AUC :  0.7219037219844997
AUC :  0.7878059784633759
AUC :  0.578825622798072
AUC :  0.5452644552179973
AUC :  0.6359427811473926
AUC :  0.6306016359261913
AUC :  0.6450169733372577
AUC :  0.6398312532454333
AUC :  0.7331789183836935
AUC :  0.6174406250477721
AUC :  0.5935393060001728
AUC :  0.5747260520712253
AUC :  0.7006654565861352
AUC :  0.7018338654305222
AUC :  0.7189207146160698
AUC :  0.6942371438260139
AUC :  0.6587747754190617
AUC :  0.6150289465326855
AUC :  0.7404296798467976
AUC :  0.5808148599429293
AUC :  0.6010477100843752
AUC :  0.6041575270378869
AUC :  0.5938343858712714
AUC :  0.6150734763119758
AUC :  0.5721471950799526
AUC :  0.6204519029597246
AUC :  0.6434134942397307
AUC :  0.6009875925134488
AUC :  0.5119504170662642
AUC :  0.6021733616804139
AUC :  0.573035310245003
AUC :  0.6138897153545695
AUC :  0.6211955426339422
AUC :  0.5423216667019413
AUC :  0.6659170064406189
AUC :  0.6374677641396002
AUC :  0.6531517005415777
AUC :  0.75899520262089
AUC :  0.6099455479087732
AUC :  0.7003093607196095
AUC :  0.7126182182664718
AUC :  0.7165819089007772
AUC :  0.6170489454271394
AUC :  0.6514105984087504
AUC :  0.6282696982617731
AUC :  0.6217850825027551
AUC :  0.6888000785853525
AUC :  0.7277834883737813
AUC :  0.7584303765889325
AUC :  0.655081718077472
AUC :  0.6397100004914771
AUC :  0.6880843914251156
AUC :  0.6906881907332043
AUC :  0.7200734739881356
AUC :  0.5548119408112269
AUC :  0.6080151247577676
AUC :  0.59548435158338
AUC :  0.651177674565038
AUC :  0.6263789957299188
AUC :  0.6128394215630218
AUC :  0.6865694666720105
AUC :  0.7143475903578428
AUC :  0.6316458466037362
AUC :  0.7026881007895942
AUC :  0.6345265984816237
AUC :  0.6539350521879413
AUC :  0.6092333007929687
AUC :  0.6385084802712613
AUC :  0.6256996580479184
AUC :  0.5950386951390281
AUC :  0.6190574586538211
AUC :  0.6045818349717131
AUC :  0.6448231086844228
AUC :  0.6046149400353553
AUC :  0.6750777039200974
AUC :  0.7301189921026774
AUC :  0.7072427656591901
AUC :  0.756557040468868
AUC :  0.7148688513419422
AUC :  0.6204922123139186
AUC :  0.6374177269066529
AUC :  0.659638925875814
AUC :  0.7016000676615571
AUC :  0.5528607496565205
AUC :  0.7521239152146734
AUC :  0.7229634411900041
AUC :  0.7195457887629368
AUC :  0.7236875515307912
AUC :  0.7294353225756323
AUC :  0.646077856255172
AUC :  0.6514633360257667
AUC :  0.6041960356587055
AUC :  0.6512333272991044
AUC :  0.5222577036799223
AUC :  0.7060080365110778
AUC :  0.6782921365485506
AUC :  0.710105122659718
AUC :  0.5978613583710128
AUC :  0.5866808030220086
AUC :  0.6050771026739852
AUC :  0.5569516130817207
AUC :  0.6017810328236084
AUC :  0.5634770964864315
AUC :  0.5796676572262243
AUC :  0.6345009237934427
AUC :  0.6198485371956366
AUC :  0.671641674781575
AUC :  0.7181594779762515
AUC :  0.7471911136173387
AUC :  0.6593877664109089
AUC :  0.6845443785314048
AUC :  0.6412145779963767
AUC :  0.7173635773330523
AUC :  0.755136588183512
AUC :  0.6986203533764307
AUC :  0.7073782018384129
AUC :  0.6750881169986265
AUC :  0.6893908834896743
AUC :  0.6988988841678991
AUC :  0.7988457131521252
AUC :  0.6810130329392572
AUC :  0.7144897062398886
AUC :  0.6596664509110075
AUC :  0.7482758576161755
AUC :  0.7588158590739733
AUC :  0.7739724547066091
AUC :  0.7462479738230547
AUC :  0.7232340224163163
AUC :  0.6681656031345999
AUC :  0.7000033724935075
AUC :  0.6606508105471579
AUC :  0.715748283431377
AUC :  0.7577445777685466
AUC :  0.800466281744525
AUC :  0.7378858160367956
AUC :  0.7266198867561335
AUC :  0.7045886534871251
AUC :  0.7144525692842949
AUC :  0.8012415653370091
AUC :  0.7316786622763011
AUC :  0.7154759773613627
AUC :  0.7027600320424147
AUC :  0.7113422247273535
AUC :  0.7438284770669714
AUC :  0.7377043255506259
AUC :  0.7566289486019165
AUC :  0.7144565381028143
AUC :  0.7312037886769917
AUC :  0.705309769137729
AUC :  0.7656356204610532
AUC :  0.8055524495281414
AUC :  0.8119606553013019
AUC :  0.757304864043271
AUC :  0.7389703586979746
AUC :  0.779949082711341
AUC :  0.759046476094322
AUC :  0.8034484382493872
AUC :  0.7720903420944573
AUC :  0.837158124784934
AUC :  0.8027338394174798
AUC :  0.806356679348606
AUC :  0.7947014852975276
AUC :  0.8034428307073869
AUC :  0.7876836948717972
AUC :  0.7481184829543293
AUC :  0.7817358346037742
AUC :  0.8200842644819228
AUC :  0.7783020033633039
AUC :  0.7883739962050247
AUC :  0.7769219714618562
AUC :  0.7429008533355486
AUC :  0.7689251154573494
AUC :  0.8481725138130529
AUC :  0.8521479289679003
AUC :  0.8279784200381988
AUC :  0.8101342717194356
AUC :  0.7828488612497638
AUC :  0.7993370773967795
AUC :  0.7966703411133284
AUC :  0.7009562171352364
AUC :  0.7306334602450044
AUC :  0.7855192182771364
AUC :  0.786757486261127
AUC :  0.794841451539145
AUC :  0.7609896745043707
Traceback (most recent call last):
  File "train_restore_MAP_NN.py", line 156, in <module>
    AUC = roc_auc_score(y_true, y_pred)
  File "/scratch_net/biwidl214/jonatank/anaconda3/envs/JKMT/lib/python3.7/site-packages/sklearn/metrics/_ranking.py", line 369, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/scratch_net/biwidl214/jonatank/anaconda3/envs/JKMT/lib/python3.7/site-packages/sklearn/utils/validation.py", line 578, in check_array
    allow_nan=force_all_finite == 'allow-nan')
  File "/scratch_net/biwidl214/jonatank/anaconda3/envs/JKMT/lib/python3.7/site-packages/sklearn/utils/validation.py", line 60, in _assert_all_finite
    msg_dtype if msg_dtype is not None else X.dtype)
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
